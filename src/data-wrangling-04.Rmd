---
title: "Data wrangling with R - P2 Data Curation"
author: "Sumy V Baby, Tomasz Zielinski"
date: "2022-03-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

We continue our work with the data, now we will focus on the Population data file.

We are going to fix some of the typical problems with real data.

This and the following R-Markdown notebooks have been inspired by our real data curation work for the project about monitoring COVID virus levels in waste water around Scotland ([see project page](https://biordm.github.io/COVID-Wastewater-Scotland/)).

Firstly,  we will read our site coordinates data and check the number of rows

```{r}
library(dplyr)
population_data <- read.csv("../raw_data/Sites_population.csv")
```
First lets have a look at the population data
```{r}
head(population_data)
```
We need only first 5 columns of the population data. Also we need to rename the population data
```{r}
population_data<-population_data[,c(1:2,4:5)]
dictionary <- data.frame(
  old_name = c("Health.Area","Site.Name","Population.Band","Population"),
  new_name = c("Health_Board","Site","Population_Band","Population")
)
renamed_population_data <- population_data
names(renamed_population_data)[match(dictionary$old_name, names(renamed_population_data))] <- dictionary$new_name
head(renamed_population_data)
```
We will first use the 'aggregate' function in base R to count the occurrence of each site

```{r}
site_count <- aggregate(renamed_population_data$Site, by=list(renamed_population_data$Site), FUN=length) 
head(site_count)
```

Now we can read the unique site names in curated data file and check for the number of sites.

```{r}

filter(site_count, x <5)

```
We got a list of sites which needs to be replaced with the correct names. Now next step is to replace the misspelled names with the corrected ones.

Now we can replace these misspelled sites with the correct names with recode function

```{r}
curated_population_data <- renamed_population_data
curated_population_data$Site <- recode(curated_population_data$Site,  "Invurie"="Inverurie", "Sheildhall"="Shieldhall","Stevenson"="Stevenston")
```
Now to make it simpler we will select the unique rows from the curated population data. We can order the data set by Site and check the resultant table
```{r}
curated_population_data <- unique(curated_population_data)
curated_population_data<- curated_population_data[order(curated_population_data$Site),]
head(curated_population_data )
```
In the table we can see there are two records of Allanfearn. One shows Health_Board as "Highland" and other has HB as well as population information as "(Empty)". This is a data entry error which needs to be rectified. Now let's take the aggregate of the data by Site and find out how many sites are like this.

```{r}
site_count <- aggregate(curated_population_data$Site, by=list(curated_population_data$Site), FUN=length) 
filter(site_count, x >1)
```
We can see clearly there are 9 sites which have this issue. The extra records with Health_Board entry as "(Empty)" needs to be removed.
In order to make sure we don't miss out any sites, lets take a look at all the all the sites for which population value is empty.

```{r}
subset(curated_population_data, curated_population_data$Population == "(Empty)")
```
Here we can see some extra sites: "Dunoon", "Haddington","Jedburgh","Oban" for which population information is missing. As these are independent sites, the population information needs to be entered. So let's first enter the population information for these sites which are missing.

```{r}
curated_population_data[which(curated_population_data$Site == "Dunoon"), ] <-c("Highland","Dunoon","4k - 10k",7830)
curated_population_data[which(curated_population_data$Site == "Haddington"), ] <- c("Lothian","Haddington","4k - 10k",9130 ) 
curated_population_data[which(curated_population_data$Site == "Jedburgh"), ] <-c("Borders","Jedburgh","2k - 4k",3910)
curated_population_data[which(curated_population_data$Site == "Oban"), ] <- c("Highland","Oban","4k - 10k",8490 ) 
```

Now we have entered the missing population information , we have again have a look at the data

```{r}
subset(curated_population_data, curated_population_data$Population == "(Empty)")
```
Now we have only 9 rows which are there because of duplication of sites. Lets remove those
```{r}
curated_population_data <- subset(curated_population_data, curated_population_data$Population != "(Empty)")
```

```{r}
curated_data <- read.csv("../data/curated_data.csv")
site_unique<-unique(select(curated_data,Health_Board,Site))
Population_data<-merge(site_unique,select(curated_population_data,Site,Population_Band,Population), by = 'Site',all=TRUE)
glimpse(Population_data)

```
Now we need to fill out the missing population information, the sites have been already arranged according to alphabetic order
```{r}
Population_data<- Population_data[order(Population_data$Site),]
for (i in 1:nrow(Population_data)) {ifelse (is.na(Population_data$Population_Band[i]),Population_data$Population_Band[i]<-x, x <- Population_data$Population_Band[i])}
for (i in 1:nrow(Population_data)) {ifelse (is.na(Population_data$Population[i]),Population_data$Population[i]<-y, y <- Population_data$Population[i])}
glimpse(Population_data)
```

The file is looking fine. Let's rearrange the columns so that Health board is arranged as first column
```{r}
library(dplyr)
Population_data <- select(Population_data,Health_Board,Site,Population_Band,Population)
head(Population_data)
```
Let's save our curated site coordinate data into a file.

```{r}
if (!file.exists('../data')) {
  dir.create(file.path('..', 'data'))  
}

fName = '../data/curated_population_data.csv'
write.csv(Population_data, fName, row.names = FALSE)
```
