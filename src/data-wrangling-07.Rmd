---
title: "Data wrangling with R - P2 Sampling sites file generation"
author: "Sumy V Baby, Tomasz Zielinski"
date: "2022-03-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

We continue our work with the data, now we will focus on prevalance time series and normalized prevalence file generation

This and the following R-Markdown notebooks have been inspired by our real data curation work for the project about monitoring COVID virus levels in waste water around Scotland ([see project page](https://biordm.github.io/COVID-Wastewater-Scotland/)).

Firstly, read our renamed data.

## Reading the data files after loading necessary libraries

We need to read the curated_site_coordinate_data.csv and curated_population_data.csv files first

```{r}
library("lubridate")
library("tidyverse")
library("tidyr")

curated_data<- read.csv("../data/curated_data.csv", check.names = F)
sampling_sites<- read.csv("../out/sampling_sites.csv")
glimpse(curated_data)
glimpse(sampling_sites)

```
We can use command `glimpse` to see all the columns (variables) and first data in each column.
Now lets select 3 columns ie. site, Date_collected and N1_Reported_value-gc_per_L

```{r}
select_curated_data<-curated_data[,c(2,3,7)]
select_norm_curated_data<-curated_data[,c(2,3,17)]
head(select_curated_data)
head(select_norm_curated_data)
```
We need to now convert the data in to a wider table format. We can use "pivot_wider" function from "tidyr" library to accomplish this. 


```{r}
curated_data_wider <- pivot_wider(select_curated_data, names_from = "Date_collected", values_from = "N1_Reported_value-gc_per_L" )
curated_norm_data_wider<- pivot_wider(select_norm_curated_data, names_from = "Date_collected", values_from = "Million_gene_copies_per_person_per_day" )
head(curated_data_wider)
head(curated_norm_data_wider)
```
We can see that it creates some warnings because for some sites the Date_collected values are duplicated . So we need to check the data more closely

```{r}
select_curated_data %>% 
group_by(Site,Date_collected) %>% 
summarize("Count" = n()) %>% filter(Count > 1)    
```
We can see clearly that for many sites the same two readings are taken on one date. This creates problem while creating the wider table as the dates are not unique for each Site. So the values these dates needs to be averaged before converting to a wider format so that we don't loose any data. Let's do the aggregate of the data by Site and Date_collected.

```{r}
Meanaggregate <- aggregate(select_curated_data$"N1_Reported_value-gc_per_L", by=list(Site=select_curated_data$Site, Date= select_curated_data$Date_collected), FUN=mean, na.rm=TRUE)
Meanaggregate_norm <- aggregate(select_norm_curated_data$Million_gene_copies_per_person_per_day, by=list(Site=select_norm_curated_data$Site, Date= select_norm_curated_data$Date_collected), FUN=mean, na.rm=TRUE)
head(Meanaggregate)
head(Meanaggregate_norm)
```
```{r}
curated_data_wider <- pivot_wider(Meanaggregate, names_from = "Date", values_from = x )
curated_norm_data_wider<- pivot_wider(Meanaggregate_norm, names_from = "Date", values_from = x)
head(curated_data_wider)
head(curated_norm_data_wider)
```

```{r}
curated_data_wider<-column_to_rownames(curated_data_wider, var = "Site") 
curated_data_wider<-curated_data_wider[,order(colnames(curated_data_wider))]
curated_norm_data_wider<-column_to_rownames(curated_norm_data_wider, var = "Site") 
curated_norm_data_wider<-curated_norm_data_wider[,order(colnames(curated_norm_data_wider))]
```

We have ordered the files by column names. For using merge function we need to convert back rownames to column
```{r}
curated_data_wider<-rownames_to_column(curated_data_wider, var = "Site") 
curated_norm_data_wider<-rownames_to_column(curated_norm_data_wider, var = "Site") 
```
Now let's merge it with the sampling site data

```{r}
#sampling_sites<-select(sampling_sites,Health_Board,Site,Latitude_dd,Longitude_dd,Population,Population_Band)

Prevalance_time_series<-full_join(select(sampling_sites,Health_Board,Site,Latitude_dd,Longitude_dd,Population,Population_Band),curated_data_wider, by = "Site")
Prevalance_norm_time_series<-full_join(select(sampling_sites,Health_Board,Site,Latitude_dd,Longitude_dd,Population,Population_Band),curated_norm_data_wider, by = "Site")
#head(View(Prevalance_time_series))


```

```{r}
if (!file.exists('../out')) {
  dir.create(file.path('..', 'out'))  
}

fName1 = '../out/prevalence_timeseries.csv'
fName2 = '../out/normprevalence_timeseries.csv'
write.csv(Prevalance_time_series, fName1, row.names = FALSE)
write.csv(Prevalance_norm_time_series, fName2, row.names = FALSE)
```

